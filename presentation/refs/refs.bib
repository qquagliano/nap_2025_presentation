
@article{alkaissi_artificial_2023,
	title = {Artificial Hallucinations in {ChatGPT}: Implications in Scientific Writing},
	issn = {2168-8184},
	url = {https://www.cureus.com/articles/138667-artificial-hallucinations-in-chatgpt-implications-in-scientific-writing},
	doi = {10.7759/cureus.35179},
	shorttitle = {Artificial Hallucinations in {ChatGPT}},
	abstract = {While still in its infancy, {ChatGPT} (Generative Pretrained Transformer), introduced in November 2022, is bound to hugely impact many industries, including healthcare, medical education, biomedical research, and scientific writing. Implications of {ChatGPT}, that new chatbot introduced by {OpenAI} on academic writing, is largely unknown. In response to the Journal of Medical Science (Cureus) Turing Test - call for case reports written with the assistance of {ChatGPT}, we present two cases one of homocystinuria-associated osteoporosis, and the other is on late-onset Pompe disease ({LOPD}), a rare metabolic disorder. We tested {ChatGPT} to write about the pathogenesis of these conditions. We documented the positive, negative, and rather troubling aspects of our newly introduced chatbot’s performance.},
	journaltitle = {Cureus},
	author = {Alkaissi, Hussam and {McFarlane}, Samy I},
	urldate = {2025-06-13},
	date = {2023-02-19},
	langid = {english},
	file = {PDF:/home/alkaline/Zotero/storage/V4VUJRFA/Alkaissi and McFarlane - 2023 - Artificial Hallucinations in ChatGPT Implications in Scientific Writing.pdf:application/pdf},
}

@article{an_comprehensive_2023,
	title = {A Comprehensive Review on Machine Learning in Healthcare Industry: Classification, Restrictions, Opportunities and Challenges},
	volume = {23},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/9/4178},
	doi = {10.3390/s23094178},
	shorttitle = {A Comprehensive Review on Machine Learning in Healthcare Industry},
	abstract = {Recently, various sophisticated methods, including machine learning and artificial intelligence, have been employed to examine health-related data. Medical professionals are acquiring enhanced diagnostic and treatment abilities by utilizing machine learning applications in the healthcare domain. Medical data have been used by many researchers to detect diseases and identify patterns. In the current literature, there are very few studies that address machine learning algorithms to improve healthcare data accuracy and efficiency. We examined the effectiveness of machine learning algorithms in improving time series healthcare metrics for heart rate data transmission (accuracy and efficiency). In this paper, we reviewed several machine learning algorithms in healthcare applications. After a comprehensive overview and investigation of supervised and unsupervised machine learning algorithms, we also demonstrated time series tasks based on past values (along with reviewing their feasibility for both small and large datasets).},
	pages = {4178},
	number = {9},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {An, Qi and Rahman, Saifur and Zhou, Jingwen and Kang, James Jin},
	urldate = {2025-06-13},
	date = {2023-04-22},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/WBXL68U3/An et al. - 2023 - A Comprehensive Review on Machine Learning in Healthcare Industry Classification, Restrictions, Opp.pdf:application/pdf},
}

@book{barocas_fairness_2023,
	title = {Fairness and Machine Learning: Limitations and Opportunities},
	url = {https://fairmlbook.org/},
	publisher = {{MIT} Press},
	author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
	date = {2023},
	langid = {english},
	keywords = {⛔ No {DOI} found},
	file = {PDF:/home/alkaline/Zotero/storage/NQC986CV/Barocas et al. - Fairness and Machine Learning.pdf:application/pdf},
}

@article{battista_artificial_2020,
	title = {Artificial intelligence and neuropsychological measures: The case of Alzheimer’s disease},
	volume = {114},
	issn = {01497634},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763420303912},
	doi = {10.1016/j.neubiorev.2020.04.026},
	shorttitle = {Artificial intelligence and neuropsychological measures},
	pages = {211--228},
	journaltitle = {Neuroscience \& Biobehavioral Reviews},
	shortjournal = {Neuroscience \& Biobehavioral Reviews},
	author = {Battista, Petronilla and Salvatore, Christian and Berlingeri, Manuela and Cerasa, Antonio and Castiglioni, Isabella},
	urldate = {2025-06-13},
	date = {2020-07},
	langid = {english},
}

@article{bzdok_statistics_2018,
	title = {Statistics versus machine learning},
	volume = {15},
	rights = {http://www.springer.com/tdm},
	issn = {1548-7091, 1548-7105},
	url = {https://www.nature.com/articles/nmeth.4642},
	doi = {10.1038/nmeth.4642},
	pages = {233--234},
	number = {4},
	journaltitle = {Nature Methods},
	shortjournal = {Nat Methods},
	author = {Bzdok, Danilo and Altman, Naomi and Krzywinski, Martin},
	urldate = {2025-06-13},
	date = {2018-04},
	langid = {english},
	file = {Accepted Version:/home/alkaline/Zotero/storage/QPS84DQ5/Bzdok et al. - 2018 - Statistics versus machine learning.pdf:application/pdf},
}

@article{catalina_knowledge_2023,
	title = {Knowledge and perception of primary care healthcare professionals on the use of artificial intelligence as a healthcare tool},
	volume = {9},
	issn = {2055-2076, 2055-2076},
	url = {https://journals.sagepub.com/doi/10.1177/20552076231180511},
	doi = {10.1177/20552076231180511},
	abstract = {Objective
              The rapid digitisation of healthcare data and the sheer volume being generated means that artificial intelligence ({AI}) is becoming a new reality in the practice of medicine. For this reason, describing the perception of primary care ({PC}) healthcare professionals on the use of {AI} as a healthcare tool and its impact in radiology is crucial to ensure its successful implementation.
            
            
              Methods
              Observational cross-sectional study, using the validated Shinners Artificial Intelligence Perception survey, aimed at all {PC} medical and nursing professionals in the health region of Central Catalonia.
            
            
              Results
              The survey was sent to 1068 health professionals, of whom 301 responded. And 85.7\% indicated that they understood the concept of {AI} but there were discrepancies in the use of this tool; 65.8\% indicated that they had not received any {AI} training and 91.4\% that they would like to receive training. The mean score for the professional impact of {AI} was 3.62 points out of 5 (standard deviation ({SD})  =  0.72), with a higher score among practitioners who had some prior knowledge of and interest in {AI}. The mean score for preparedness for {AI} was 2.76 points out of 5 ({SD}  =  0.70), with higher scores for nursing and those who use or do not know if they use {AI}.
            
            
              Conclusions
              The results of this study show that the majority of professionals understood the concept of {AI}, perceived its impact positively, and felt prepared for its implementation. In addition, despite being limited to a diagnostic aid, the implementation of {AI} in radiology was a high priority for these professionals.},
	pages = {20552076231180511},
	journaltitle = {Digital Health},
	shortjournal = {{DIGITAL} {HEALTH}},
	author = {Catalina, Queralt Miró and Fuster-Casanovas, Aïna and Vidal-Alaball, Josep and Escalé-Besa, Anna and Marin-Gomez, Francesc X and Femenia, Joaquim and Solé-Casals, Jordi},
	urldate = {2025-06-13},
	date = {2023-01},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/MI2P9X5G/Catalina et al. - 2023 - Knowledge and perception of primary care healthcare professionals on the use of artificial intellige.pdf:application/pdf},
}

@article{chen_generative_2024,
	title = {Generative {AI} in Medical Practice: In-Depth Exploration of Privacy and Security Challenges},
	volume = {26},
	issn = {1438-8871},
	url = {https://www.jmir.org/2024/1/e53008},
	doi = {10.2196/53008},
	shorttitle = {Generative {AI} in Medical Practice},
	abstract = {As advances in artificial intelligence ({AI}) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative {AI} in health care becomes increasingly important. Generative {AI}, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data-intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative {AI} in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative {AI} in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative {AI} in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative {AI} systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative {AI} across diverse domains within health care, this paper contributes to theoretical discussions surrounding {AI} ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative {AI} solutions within their organizations.},
	pages = {e53008},
	journaltitle = {Journal of Medical Internet Research},
	shortjournal = {J Med Internet Res},
	author = {Chen, Yan and Esmaeilzadeh, Pouyan},
	urldate = {2025-06-13},
	date = {2024-03-08},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/Y6XSIH5Y/Chen and Esmaeilzadeh - 2024 - Generative AI in Medical Practice In-Depth Exploration of Privacy and Security Challenges.pdf:application/pdf},
}

@article{clements_prospective_2022,
	title = {A Prospective Study Assessing Patient Perception of the Use Of Artificial Intelligence in Radiology},
	rights = {https://creativecommons.org/licenses/by-nc/4.0},
	issn = {2204-3136, 1833-3818},
	url = {https://journal.achsm.org.au/index.php/achsm/article/view/861},
	doi = {10.24083/apjhm.v17i1.861},
	abstract = {{OBJECTIVE} Radiology has been at the forefront of medical technology including the use of artificial intelligence ({AI}) and machine learning. However, there remains scant literature on the perspective of patients regarding clinical use of this technology. This study aimed to assess the opinion of radiology patients on the potential involvement of {AI} in the ir medical care. {DESIGN} A survey was given to ambulatory outpatients attending our hospital for medical imaging. The survey consisted of questions concerning comfort with radiologist reports, comfort with entirely {AI} reports, comfort with in -part {AI} reports, accuracy, data security, and medicolegal risk. {SETTING} Tertiary academic hospital in Melbourne, Australia. {MAIN} {OUTCOME} {MEASURES} Patients were surveyed for their overall comfort with the use of {AI} in their medical imaging using a Likert scale of 0 to 7.
{RESULTS} 283 patient surveys were included. Patients rated comfort in their imaging being reported by a radiologist at mean of 6.5 out of 7, compared with {AI} alone at mean 3.5 out of 7 (p{\textless}0.0001), or in-part {AI} at mean 5.4 out of 7 (p{\textless}0.0001). Patients felt {AI} should have an accuracy of mean 91.4\% to be able to be used in a clinical environment. Patients rated their current comfort with data security at mean 5.5 out of 7 however comfort with data security using {AI} at mean 4.4 out of 7, p{\textless}0.0001.
{CONCLUSIONS} Patients are trusting of the holistic role of a radiologist however, remain uncomfortable with clinical use of {AI} as a standalone product including accuracy and data security. If {AI} technology is to evolve then it must do so with appropriate involvement of stakeholders, of which patients are paramount.},
	journaltitle = {Asia Pacific Journal of Health Management},
	shortjournal = {{APJHM}},
	author = {Clements, Warren and Thong, Louisa and Zia, Adil and Moriarty, Heather and Goh, Gerard},
	urldate = {2025-06-13},
	date = {2022-04-07},
	langid = {english},
	file = {PDF:/home/alkaline/Zotero/storage/LRPQJY5H/Clements et al. - 2022 - A Prospective Study Assessing Patient Perception of the Use Of Artificial Intelligence in Radiology.pdf:application/pdf},
}

@book{crawford_atlas_2021,
	location = {New Haven London},
	title = {Atlas of {AI}: power, politics, and the planetary costs of artificial intelligence},
	isbn = {978-0-300-26463-0 978-0-300-25239-2},
	shorttitle = {Atlas of {AI}},
	abstract = {The hidden costs of artificial intelligence, from natural resources and labor to privacy and freedom What happens when artificial intelligence saturates political life and depletes the planet? How is {AI} shaping our understanding of ourselves and our societies? In this book Kate Crawford reveals how this planetary network is fueling a shift toward undemocratic governance and increased inequality. Drawing on more than a decade of research, award+'winning science, and technology, Crawford reveals how {AI} is a technology of extraction: from the energy and minerals needed to build and sustain its infrastructure, to the exploited workers behind "automated" services, to the data {AI} collects from us. Rather than taking a narrow focus on code and algorithms, Crawford offers us a political and a material perspective on what it takes to make artificial intelligence and where it goes wrong. While technical systems present a veneer of objectivity, they are always systems of power. This is an urgent account of what is at stake as technology companies use artificial intelligence to reshape the world},
	pagetotal = {1},
	publisher = {Yale University Press},
	author = {Crawford, Kate},
	date = {2021},
	file = {Table of Contents PDF:/home/alkaline/Zotero/storage/XD8PR9IX/Crawford - 2021 - Atlas of AI power, politics, and the planetary costs of artificial intelligence.pdf:application/pdf},
}

@article{hedderich_ai_2021,
	title = {{AI} for Doctors—A Course to Educate Medical Professionals in Artificial Intelligence for Medical Imaging},
	volume = {9},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2227-9032},
	url = {https://www.mdpi.com/2227-9032/9/10/1278},
	doi = {10.3390/healthcare9101278},
	abstract = {Successful adoption of artificial intelligence ({AI}) in medical imaging requires medical professionals to understand underlying principles and techniques. However, educational offerings tailored to the need of medical professionals are scarce. To fill this gap, we created the course “{AI} for Doctors: Medical Imaging”. An analysis of participants’ opinions on {AI} and self-perceived skills rated on a five-point Likert scale was conducted before and after the course. The participants’ attitude towards {AI} in medical imaging was very optimistic before and after the course. However, deeper knowledge of {AI} and the process for validating and deploying it resulted in significantly less overoptimism with respect to perceivable patient benefits through {AI} (p = 0.020). Self-assessed skill ratings significantly improved after the course, and the appreciation of the course content was very positive. However, we observed a substantial drop-out rate, mostly attributed to the lack of time of medical professionals. There is a high demand for educational offerings regarding {AI} in medical imaging among medical professionals, and better education may lead to a more realistic appreciation of clinical adoption. However, time constraints imposed by a busy clinical schedule need to be taken into account for successful education of medical professionals.},
	pages = {1278},
	number = {10},
	journaltitle = {Healthcare},
	shortjournal = {Healthcare},
	author = {Hedderich, Dennis M. and Keicher, Matthias and Wiestler, Benedikt and Gruber, Martin J. and Burwinkel, Hendrik and Hinterwimmer, Florian and Czempiel, Tobias and Spiro, Judith E. and Pinto Dos Santos, Daniel and Heim, Dominik and Zimmer, Claus and Rückert, Daniel and Kirschke, Jan S. and Navab, Nassir},
	urldate = {2025-06-13},
	date = {2021-09-28},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/V78JIWPZ/Hedderich et al. - 2021 - AI for Doctors—A Course to Educate Medical Professionals in Artificial Intelligence for Medical Imag.pdf:application/pdf},
}

@article{jiang_artificial_2017,
	title = {Artificial intelligence in healthcare: past, present and future},
	volume = {2},
	issn = {2059-8688, 2059-8696},
	url = {https://svn.bmj.com/lookup/doi/10.1136/svn-2017-000101},
	doi = {10.1136/svn-2017-000101},
	shorttitle = {Artificial intelligence in healthcare},
	abstract = {Artificial intelligence ({AI}) aims to mimic human cognitive functions. It is bringing a paradigm shift to healthcare, powered by increasing availability of healthcare data and rapid progress of analytics techniques. We survey the current status of {AI} applications in healthcare and discuss its future. {AI} can be applied to various types of healthcare data (structured and unstructured). Popular {AI} techniques include machine learning methods for structured data, such as the classical support vector machine and neural network, and the modern deep learning, as well as natural language processing for unstructured data. Major disease areas that use {AI} tools include cancer, neurology and cardiology. We then review in more details the {AI} applications in stroke, in the three major areas of early detection and diagnosis, treatment, as well as outcome prediction and prognosis evaluation. We conclude with discussion about pioneer {AI} systems, such as {IBM} Watson, and hurdles for real-life deployment of {AI}.},
	pages = {230--243},
	number = {4},
	journaltitle = {Stroke and Vascular Neurology},
	shortjournal = {Stroke Vasc Neurol},
	author = {Jiang, Fei and Jiang, Yong and Zhi, Hui and Dong, Yi and Li, Hao and Ma, Sufeng and Wang, Yilong and Dong, Qiang and Shen, Haipeng and Wang, Yongjun},
	urldate = {2025-06-13},
	date = {2017-12},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/4GAXJX7U/Jiang et al. - 2017 - Artificial intelligence in healthcare past, present and future.pdf:application/pdf},
}

@article{kim_development_2024,
	title = {Development of an eye-tracking system based on a deep learning model to assess executive function in patients with mental illnesses},
	volume = {14},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-68586-2},
	doi = {10.1038/s41598-024-68586-2},
	pages = {18186},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Kim, Minah and Lee, Jungha and Lee, Soo Yong and Ha, Minji and Park, Inkyung and Jang, Jiseon and Jang, Moonyoung and Park, Sunghyun and Kwon, Jun Soo},
	urldate = {2025-06-13},
	date = {2024-08-06},
	langid = {english},
	file = {Full Text PDF:/home/alkaline/Zotero/storage/72GRF5BU/Kim et al. - 2024 - Development of an eye-tracking system based on a deep learning model to assess executive function in.pdf:application/pdf},
}

@article{kim_digital_2024,
	title = {Digital quantification of the {MMSE} interlocking pentagon areas: a three-stage algorithm},
	volume = {14},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-59194-1},
	doi = {10.1038/s41598-024-59194-1},
	shorttitle = {Digital quantification of the {MMSE} interlocking pentagon areas},
	abstract = {Abstract
            
              The Mini-Mental State Examination ({MMSE}) is a widely employed screening tool for the severity of cognitive impairment. Among the {MMSE} items, the pentagon copying test ({PCT}) requires participants to accurately replicate a sample of two interlocking pentagons. While the {PCT} is traditionally scored on a binary scale, there have been limited developments of granular scoring scale to assess task performance. In this paper, we present a novel three-stage algorithm, called Quantification of Interlocking Pentagons ({QIP}) which quantifies {PCT} performance by computing the areas of individual pentagons and their intersection areas, and a balance ratio between the areas of the two individual pentagons. The three stages of the {QIP} algorithm include: (1) detection of line segments, (2) unraveling of the interlocking pentagons, and (3) quantification of areas. A set of 497 {PCTs} from 84 participants including their baseline and follow-up {PCTs} from the Rush Memory and Aging Project was selected blinded about their cognitive and clinical status. Analysis of the quantified data revealed a significant inverse relationship between age and balance ratio  (beta = − 0.49,
              p
               = 0.0033), indicating that older age was associated with a smaller balance ratio. In addition, balance ratio was associated with  perceptual speed (r = 0.71,
              p
               = 0.0135), vascular risk factors (beta = − 3.96,
              p
               = 0.0269), and medical conditions (beta = − 2.78,
              p
               = 0.0389). The {QIP} algorithm can serve as a useful tool for enhancing the scoring of performance in the {PCT}.},
	pages = {9038},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Kim, Namhee and Truty, Timothy and Duke Han, S. and Heo, Moonseong and Buchman, Aron S. and Bennett, David A. and Tasaki, Shinya},
	urldate = {2025-06-13},
	date = {2024-04-19},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/87V8SBP7/Kim et al. - 2024 - Digital quantification of the MMSE interlocking pentagon areas a three-stage algorithm.pdf:application/pdf},
}

@article{kuhl_artificial_2022,
	title = {Artificial intelligence and machine learning},
	volume = {32},
	issn = {1019-6781, 1422-8890},
	url = {https://link.springer.com/10.1007/s12525-022-00598-0},
	doi = {10.1007/s12525-022-00598-0},
	abstract = {Abstract
            Within the last decade, the application of “artificial intelligence” and “machine learning” has become popular across multiple disciplines, especially in information systems. The two terms are still used inconsistently in academia and industry—sometimes as synonyms, sometimes with different meanings. With this work, we try to clarify the relationship between these concepts. We review the relevant literature and develop a conceptual framework to specify the role of machine learning in building (artificial) intelligent agents. Additionally, we propose a consistent typology for {AI}-based information systems. We contribute to a deeper understanding of the nature of both concepts and to more terminological clarity and guidance—as a starting point for interdisciplinary discussions and future research.},
	pages = {2235--2244},
	number = {4},
	journaltitle = {Electronic Markets},
	shortjournal = {Electron Markets},
	author = {Kühl, Niklas and Schemmer, Max and Goutier, Marc and Satzger, Gerhard},
	urldate = {2025-06-13},
	date = {2022-12},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/GEQLUZG4/Kühl et al. - 2022 - Artificial intelligence and machine learning.pdf:application/pdf},
}

@article{langer_ai_nodate,
	title = {The {AI} Neuropsychologist: Automatic scoring of memory deficits with deep learning},
	author = {Langer, Nicolas and Weber, Maurice and Vieira, Bruno Hebling and Strzelczyk, Dawid and Wolf, Lukas and Pedroni, Andreas and Heitz, Jonathan and Müller, Stephan and Schultheiss, Christoph and Tröndle, Marius and Lasprilla, Carlos Arango and Rivera, Diego and Scarpina, Federica and Zhao, Qianhua and Leuthold, Rico and Jenni, Oskar G and Brugger, Peter and Zaehle, Tino and Lorenz, Romy and Zhang, Ce},
	langid = {english},
	keywords = {⛔ No {DOI} found},
	file = {PDF:/home/alkaline/Zotero/storage/7Y7B4CU2/Langer et al. - The AI Neuropsychologist Automatic scoring of memory deficits with deep learning.pdf:application/pdf},
}

@article{lavery_cognitive_2007,
	title = {Cognitive Assessment of Older Primary Care Patients with and Without Memory Complaints},
	volume = {22},
	rights = {http://www.springer.com/tdm},
	issn = {0884-8734, 1525-1497},
	url = {http://link.springer.com/10.1007/s11606-007-0198-0},
	doi = {10.1007/s11606-007-0198-0},
	pages = {949--954},
	number = {7},
	journaltitle = {Journal of General Internal Medicine},
	shortjournal = {J {GEN} {INTERN} {MED}},
	author = {Lavery, Laurie L. and Lu, Shu-ya and Chang, Chung-Chou H. and Saxton, Judith and Ganguli, Mary},
	urldate = {2025-06-13},
	date = {2007-06-05},
	langid = {english},
}

@article{park_automating_2023,
	title = {Automating Rey Complex Figure Test scoring using a deep learning-based approach: a potential large-scale screening tool for cognitive decline},
	volume = {15},
	issn = {1758-9193},
	url = {https://alzres.biomedcentral.com/articles/10.1186/s13195-023-01283-w},
	doi = {10.1186/s13195-023-01283-w},
	shorttitle = {Automating Rey Complex Figure Test scoring using a deep learning-based approach},
	abstract = {Abstract
            
              Background
              The Rey Complex Figure Test ({RCFT}) has been widely used to evaluate the neurocognitive functions in various clinical groups with a broad range of ages. However, despite its usefulness, the scoring method is as complex as the figure. Such a complicated scoring system can lead to the risk of reducing the extent of agreement among raters. Although several attempts have been made to use {RCFT} in clinical settings in a digitalized format, little attention has been given to develop direct automatic scoring that is comparable to experienced psychologists. Therefore, we aimed to develop an artificial intelligence ({AI}) scoring system for {RCFT} using a deep learning ({DL}) algorithm and confirmed its validity.
            
            
              Methods
              
                A total of 6680 subjects were enrolled in the Gwangju Alzheimer’s and Related Dementia cohort registry, Korea, from January 2015 to June 2021. We obtained 20,040 scanned images using three images per subject (copy, immediate recall, and delayed recall) and scores rated by 32 experienced psychologists. We trained the automated scoring system using the {DenseNet} architecture. To increase the model performance, we improved the quality of training data by re-examining some images with poor results (mean absolute error ({MAE})
                
                  
                    \$\${\textbackslash}ge\$\$
                    
                      ≥
                    
                  
                
                5 [points]) and re-trained our model. Finally, we conducted an external validation with 150 images scored by five experienced psychologists.
              
            
            
              Results
              
                For fivefold cross-validation, our first model obtained {MAE} = 1.24 [points] and
                R
                -squared (
                
                  
                    \$\$\{R\}{\textasciicircum}\{2\}\$\$
                    
                      
                        
                          R
                        
                        2
                      
                    
                  
                
                ) = 0.977. However, after evaluating and updating the model, the performance of the final model was improved ({MAE} = 0.95 [points],
                
                  
                    \$\$\{R\}{\textasciicircum}\{2\}\$\$
                    
                      
                        
                          R
                        
                        2
                      
                    
                  
                
                = 0.986). Predicted scores among cognitively normal, mild cognitive impairment, and dementia were significantly different. For the 150 independent test sets, the {MAE} and
                
                  
                    \$\$\{R\}{\textasciicircum}\{2\}\$\$
                    
                      
                        
                          R
                        
                        2
                      
                    
                  
                
                between {AI} and average scores by five human experts were 0.64 [points] and 0.994, respectively.
              
            
            
              Conclusion
              We concluded that there was no fundamental difference between the rating scores of experienced psychologists and those of our {AI} scoring system. We expect that our {AI} psychologist will be able to contribute to screen the early stages of Alzheimer’s disease pathology in medical checkup centers or large-scale community-based research institutes in a faster and cost-effective way.},
	pages = {145},
	number = {1},
	journaltitle = {Alzheimer's Research \& Therapy},
	shortjournal = {Alz Res Therapy},
	author = {Park, Jun Young and Seo, Eun Hyun and Yoon, Hyung-Jun and Won, Sungho and Lee, Kun Ho},
	urldate = {2025-06-13},
	date = {2023-08-30},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/KAPLYEE8/Park et al. - 2023 - Automating Rey Complex Figure Test scoring using a deep learning-based approach a potential large-s.pdf:application/pdf},
}

@article{poon_opening_2021,
	title = {Opening the black box of {AI}‐Medicine},
	volume = {36},
	issn = {0815-9319, 1440-1746},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/jgh.15384},
	doi = {10.1111/jgh.15384},
	abstract = {Abstract
            One of the biggest challenges of utilizing artificial intelligence ({AI}) in medicine is that physicians are reluctant to trust and adopt something that they do not fully understand and regarded as a “black box.” Machine Learning ({ML}) can assist in reading radiological, endoscopic and histological pictures, suggesting diagnosis and predict disease outcome, and even recommending therapy and surgical decisions. However, clinical adoption of these {AI} tools has been slow because of a lack of trust. Besides clinician's doubt, patients lacking confidence with {AI}‐powered technologies also hamper development. While they may accept the reality that human errors can occur, little tolerance of machine error is anticipated. In order to implement {AI} medicine successfully, interpretability of {ML} algorithm needs to improve. Opening the black box in {AI} medicine needs to take a stepwise approach. Small steps of biological explanation and clinical experience in {ML} algorithm can help to build trust and acceptance. {AI} software developers will have to clearly demonstrate that when the {ML} technologies are integrated into the clinical decision‐making process, they can actually help to improve clinical outcome. Enhancing interpretability of {ML} algorithm is a crucial step in adopting {AI} in medicine.},
	pages = {581--584},
	number = {3},
	journaltitle = {Journal of Gastroenterology and Hepatology},
	shortjournal = {J of Gastro and Hepatol},
	author = {Poon, Aaron I F and Sung, Joseph J Y},
	urldate = {2025-06-13},
	date = {2021-03},
	langid = {english},
}

@article{tasaki_explainable_2023,
	title = {Explainable deep learning approach for extracting cognitive features from hand-drawn images of intersecting pentagons},
	volume = {6},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-023-00904-w},
	doi = {10.1038/s41746-023-00904-w},
	abstract = {Abstract
            Hand drawing, which requires multiple neural systems for planning and controlling sequential movements, is a useful cognitive test for older adults. However, the conventional visual assessment of these drawings only captures limited attributes and overlooks subtle details that could help track cognitive states. Here, we utilized a deep-learning model, {PentaMind}, to examine cognition-related features from hand-drawn images of intersecting pentagons. {PentaMind}, trained on 13,777 images from 3111 participants in three aging cohorts, explained 23.3\% of the variance in the global cognitive scores, 1.92 times more than the conventional rating. This accuracy improvement was due to capturing additional drawing features associated with motor impairments and cerebrovascular pathologies. By systematically modifying the input images, we discovered several important drawing attributes for cognition, including line waviness. Our results demonstrate that deep learning models can extract novel drawing metrics to improve the assessment and monitoring of cognitive decline and dementia in older adults.},
	pages = {157},
	number = {1},
	journaltitle = {npj Digital Medicine},
	shortjournal = {npj Digit. Med.},
	author = {Tasaki, Shinya and Kim, Namhee and Truty, Tim and Zhang, Ada and Buchman, Aron S. and Lamar, Melissa and Bennett, David A.},
	urldate = {2025-06-13},
	date = {2023-08-23},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/8JKHLZ2B/Tasaki et al. - 2023 - Explainable deep learning approach for extracting cognitive features from hand-drawn images of inter.pdf:application/pdf},
}

@article{toh_looking_2019,
	title = {Looking beyond the hype: Applied {AI} and machine learning in translational medicine},
	volume = {47},
	issn = {23523964},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352396419305493},
	doi = {10.1016/j.ebiom.2019.08.027},
	shorttitle = {Looking beyond the hype},
	pages = {607--615},
	journaltitle = {{EBioMedicine}},
	shortjournal = {{EBioMedicine}},
	author = {Toh, Tzen S. and Dondelinger, Frank and Wang, Dennis},
	urldate = {2025-06-13},
	date = {2019-09},
	langid = {english},
	file = {Full Text PDF:/home/alkaline/Zotero/storage/I6VI5P9W/Toh et al. - 2019 - Looking beyond the hype Applied AI and machine learning in translational medicine.pdf:application/pdf},
}

@article{thirunavukarasu_large_2023,
	title = {Large language models in medicine},
	volume = {29},
	issn = {1078-8956, 1546-170X},
	url = {https://www.nature.com/articles/s41591-023-02448-8},
	doi = {10.1038/s41591-023-02448-8},
	pages = {1930--1940},
	number = {8},
	journaltitle = {Nature Medicine},
	shortjournal = {Nat Med},
	author = {Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
	urldate = {2025-06-13},
	date = {2023-08},
	langid = {english},
}

@article{fuermaier_chatgpt_2025,
	title = {{ChatGPT} Helps Students Feign {ADHD}: An Analogue Study on {AI}-Assisted Coaching},
	volume = {18},
	issn = {1938-971X, 1938-9728},
	url = {https://link.springer.com/10.1007/s12207-025-09538-7},
	doi = {10.1007/s12207-025-09538-7},
	shorttitle = {{ChatGPT} Helps Students Feign {ADHD}},
	abstract = {Abstract
            
              This preregistered study aimed to assess whether {AI}-generated coaching helps students to successfully feign attention-deficit/hyperactivity disorder ({ADHD}) in adulthood. First, based on questions generated by 22 students, we conducted an extensive {ChatGPT} query to develop a concise {AI}-generated information sheet designed to coach students in feigning {ADHD} during a clinical assessment. Second, we evaluated the effect of this coaching in an experimental analogue study in which 110 university students were randomly assigned to one of three groups: (1) a control group (
              n
               = 42), (2) an {ADHD} symptom–coached simulation group (
              n
               = 35), and (3) an {AI}-coached simulation group (
              n
               = 33). All participants underwent a clinical neuropsychological assessment that included measures of {ADHD} symptoms, functional impairments, selective attention, and working memory. Our preregistered data analysis revealed that the {AI}-coached simulation group consistently moderated their symptom overreporting and cognitive underperformance compared to the symptom-coached group in small to medium size, resulting in lower detection sensitivity. We conclude that publicly accessible {AI} tools, such as current versions of chatbots, can provide clear and effective strategies for feigning {ADHD} during clinical neuropsychological assessments, posing a significant threat to the validity assessments. We recommend that researchers and clinicians exercise caution when sharing assessment materials, example items, and scoring methodologies.},
	pages = {97--107},
	number = {2},
	journaltitle = {Psychological Injury and Law},
	shortjournal = {Psychol. Inj. and Law},
	author = {Fuermaier, Anselm B. M. and Niesten, Isabella J. M.},
	urldate = {2025-06-13},
	date = {2025-06},
	langid = {english},
	file = {Full Text PDF:/home/alkaline/Zotero/storage/FMVSVFPW/Fuermaier and Niesten - 2025 - ChatGPT Helps Students Feign ADHD An Analogue Study on AI-Assisted Coaching.pdf:application/pdf},
}

@article{devine_using_2024,
	title = {Using New Science to reduce bias of Old Science: {AI}‐driven Customization of Culturally Biased Tests},
	volume = {20},
	issn = {1552-5260, 1552-5279},
	url = {https://alz-journals.onlinelibrary.wiley.com/doi/10.1002/alz.091267},
	doi = {10.1002/alz.091267},
	shorttitle = {Using New Science to reduce bias of Old Science},
	abstract = {Abstract
            
              Background
              Widely used neuropsychological test instruments are notoriously biased across the demographics of age, sex/gender, education, language and culture. This includes verbal memory tests that elicit speech such as the paragraph recall or list‐learning memory tests. Language tests are similarly biased, including the Boston Diagnostic Aphasia Examination Cookie Theft Test ({CTT}) that has been used to elicit both written and spoken responses for decades. Biased tests generate biased results, and this problem is exacerbated by the widespread practice of repurposing tests generated for those in largely high income, Westernized countries for use in other countries that are demographically and culturally distinct. We tested the use of large language model ({LLM}) tools to automatically generate verbal test stimuli that were more locally relevant.
            
            
              Methods
              Starting with the {CTT}, that involves describing a picture that contains 14 core content units, we used {ChatGPT} to aid in generating customized pictures with the same number of core content units that were more universally relevant, (e.g., open park area, beach, etc.) by suggesting parameters and integrating resulting features into new pictures. We also tested capabilities to generate pictorial scenes that are more representative of regional settings, such as the Asia Pacific or Middle East. We are testing {LLM} capacity to generate similarly regionally customized list learning stimuli that maintain the original list learning test word frequency and difficulty across languages.
            
            
              Results
              Using an iterative approach, we were able to use automated artificial intelligence ({AI})‐driven tools to rapidly generate regionally relevant test stimuli that retained the original test characteristics to preserve generation of comparable results. Descriptive comparisons found that aided by automated {AI} tool, we could generate new neuropsychological test stimuli in a matter of minutes compared to months long manual methods.
            
            
              Conclusion
              The rapid emergence of {AI} has generated significant concerns about its appropriate use for health and health care applications. Given that {AI} is here to stay, we are testing the capacity of this technological advance to address long‐standing, persistent problems in {AD} research and usher in a new era of precision brain health that has global relevance in a rapidly aging world population.},
	pages = {e091267},
	issue = {S2},
	journaltitle = {Alzheimer's \& Dementia},
	shortjournal = {Alzheimer's \&amp; Dementia},
	author = {Devine, Sherral A. and Lee, Melissa and Gurnani, Ashita S. and Sunderaraman, Preeti and Kourtis, Lampros and Pratap, Abhishek and Low, Spencer and Ho, Kristi and Gifford, Katherine A. and Au, Rhoda},
	urldate = {2025-06-13},
	date = {2024-12},
	langid = {english},
}

@article{halkiopoulos_leveraging_2024,
	title = {Leveraging {AI} in E-Learning: Personalized Learning and Adaptive Assessment through Cognitive Neuropsychology—A Systematic Analysis},
	volume = {13},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/13/18/3762},
	doi = {10.3390/electronics13183762},
	shorttitle = {Leveraging {AI} in E-Learning},
	abstract = {This paper reviews the literature on integrating {AI} in e-learning, from the viewpoint of cognitive neuropsychology, for Personalized Learning ({PL}) and Adaptive Assessment ({AA}). This review follows the {PRISMA} systematic review methodology and synthesizes the results of 85 studies that were selected from an initial pool of 818 records across several databases. The results indicate that {AI} can improve students’ performance, engagement, and motivation; at the same time, some challenges like bias and discrimination should be noted. The review covers the historic development of {AI} in education, its theoretical grounding, and its practical applications within {PL} and {AA} with high promise and ethical issues of {AI}-powered educational systems. Future directions are empirical validation of effectiveness and equity, development of algorithms that reduce bias, and exploration of ethical implications regarding data privacy. The review identifies the transformative potential of {AI} in developing personalized and adaptive learning ({AL}) environments, thus, it advocates continued development and exploration as a means to improve educational outcomes.},
	pages = {3762},
	number = {18},
	journaltitle = {Electronics},
	shortjournal = {Electronics},
	author = {Halkiopoulos, Constantinos and Gkintoni, Evgenia},
	urldate = {2025-06-13},
	date = {2024-09-22},
	langid = {english},
	file = {Full Text PDF:/home/alkaline/Zotero/storage/8IPX74V6/Halkiopoulos and Gkintoni - 2024 - Leveraging AI in E-Learning Personalized Learning and Adaptive Assessment through Cognitive Neurops.pdf:application/pdf},
}

@article{miller_technology_2017,
	title = {The Technology Crisis in Neuropsychology},
	volume = {32},
	issn = {0887-6177, 1873-5843},
	url = {http://academic.oup.com/acn/article/32/5/541/3852214/The-Technology-Crisis-in-Neuropsychology},
	doi = {10.1093/arclin/acx050},
	pages = {541--554},
	number = {5},
	journaltitle = {Archives of Clinical Neuropsychology},
	author = {Miller, Justin B. and Barr, William B.},
	urldate = {2025-06-13},
	date = {2017-08},
	langid = {english},
}

@article{singh_technology_2021,
	title = {Technology meets tradition: a hybrid model for implementing digital tools in neuropsychology},
	volume = {33},
	issn = {0954-0261, 1369-1627},
	url = {https://www.tandfonline.com/doi/full/10.1080/09540261.2020.1835839},
	doi = {10.1080/09540261.2020.1835839},
	shorttitle = {Technology meets tradition},
	pages = {382--393},
	number = {4},
	journaltitle = {International Review of Psychiatry},
	shortjournal = {International Review of Psychiatry},
	author = {Singh, Shifali and Germine, Laura},
	urldate = {2025-06-13},
	date = {2021-05-19},
	langid = {english},
}

@article{hou_physician_2024,
	title = {Physician Adoption of {AI} Assistant},
	volume = {26},
	issn = {1523-4614, 1526-5498},
	url = {https://pubsonline.informs.org/doi/10.1287/msom.2023.0093},
	doi = {10.1287/msom.2023.0093},
	abstract = {Problem definition: Artificial intelligence ({AI}) assistants—software agents that can perform tasks or services for individuals—are among the most promising {AI} applications. However, little is known about the adoption of {AI} assistants by service providers (i.e., physicians) in a real-world healthcare setting. In this paper, we investigate the impact of the {AI} smartness (i.e., whether the {AI} assistant is powered by machine learning intelligence) and the impact of {AI} transparency (i.e., whether physicians are informed of the {AI} assistant). Methodology/results: We collaborate with a leading healthcare platform to run a field experiment in which we compare physicians’ adoption behavior, that is, adoption rate and adoption timing, of smart and automated {AI} assistants under transparent and non-transparent conditions. We find that the smartness can increase the adoption rate and shorten the adoption timing, whereas the transparency can only shorten the adoption timing. Moreover, the impact of {AI} transparency on the adoption rate is contingent on the smartness level of the {AI} assistant: the transparency increases the adoption rate only when the {AI} assistant is not equipped with smart algorithms and fails to do so when the {AI} assistant is smart. Managerial implications: Our study can guide platforms in designing their {AI} strategies. Platforms should improve the smartness of {AI} assistants. If such an improvement is too costly, the platform should transparentize the {AI} assistant, especially when it is not smart.
            Funding: This research was supported by a Behavioral Research Assistance Grant from the C. T. Bauer College of Business, University of Houston. H. Zhao acknowledges support from Hong Kong General Research Fund [9043593]. Y. (R.) Tan acknowledges generous support from {CEIBS} Research [Grant {AG}24QCS].
            Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2023.0093 .},
	pages = {1639--1655},
	number = {5},
	journaltitle = {Manufacturing \& Service Operations Management},
	shortjournal = {M\&{SOM}},
	author = {Hou, Ting and Li, Meng and Tan, Yinliang (Ricky) and Zhao, Huazhong},
	urldate = {2025-06-13},
	date = {2024-09},
	langid = {english},
}

@misc{duede_oil_2024,
	title = {Oil \& Water? Diffusion of {AI} Within and Across Scientific Fields},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2405.15828},
	doi = {10.48550/ARXIV.2405.15828},
	shorttitle = {Oil \&amp; Water?},
	abstract = {This study empirically investigates claims of the increasing ubiquity of artificial intelligence ({AI}) within roughly 80 million research publications across 20 diverse scientific fields, by examining the change in scholarly engagement with {AI} from 1985 through 2022. We observe exponential growth, with {AI}-engaged publications increasing approximately thirteenfold (13x) across all fields, suggesting a dramatic shift from niche to mainstream. Moreover, we provide the first empirical examination of the distribution of {AI}-engaged publications across publication venues within individual fields, with results that reveal a broadening of {AI} engagement within disciplines. While this broadening engagement suggests a move toward greater disciplinary integration in every field, increased ubiquity is associated with a semantic tension between {AI}-engaged research and more traditional disciplinary research. Through an analysis of tens of millions of document embeddings, we observe a complex interplay between {AI}-engaged and non-{AI}-engaged research within and across fields, suggesting that increasing ubiquity is something of an oil-and-water phenomenon -- {AI}-engaged work is spreading out over fields, but not mixing well with non-{AI}-engaged work.},
	publisher = {{arXiv}},
	author = {Duede, Eamon and Dolan, William and Bauer, André and Foster, Ian and Lakhani, Karim},
	urldate = {2025-06-13},
	date = {2024},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), Digital Libraries (cs.{DL}), {FOS}: Computer and information sciences},
}

@article{emsley_chatgpt_2023,
	title = {{ChatGPT}: these are not hallucinations – they’re fabrications and falsifications},
	volume = {9},
	issn = {2754-6993},
	url = {https://www.nature.com/articles/s41537-023-00379-4},
	doi = {10.1038/s41537-023-00379-4},
	shorttitle = {{ChatGPT}},
	pages = {52, s41537--023--00379--4},
	number = {1},
	journaltitle = {Schizophrenia},
	shortjournal = {Schizophr},
	author = {Emsley, Robin},
	urldate = {2025-06-13},
	date = {2023-08-19},
	langid = {english},
	file = {Full Text:/home/alkaline/Zotero/storage/T75R7SLL/Emsley - 2023 - ChatGPT these are not hallucinations – they’re fabrications and falsifications.pdf:application/pdf},
}

@book{mitrushina_handbook_2005,
	location = {New York},
	edition = {2nd ed},
	title = {Handbook of normative data for neuropsychological assessment},
	isbn = {978-0-19-516930-0},
	publisher = {Oxford University Press},
	author = {Mitrushina, Maura and Boone, Kyle and Razani, Jill and D'Elia, Louis},
	date = {2005},
}

@book{wechsler_wais-5_2025,
	title = {{WAIS}-5 Technical \& Intepretative Manual},
	publisher = {Pearson Assessments},
	author = {Wechsler, David},
	date = {2025},
}

@book{wechsler_wms-iv_2009,
	title = {{WMS}-{IV} Technical \& Interperative Manual},
	publisher = {Pearson Assessments},
	author = {Wechsler, David},
	date = {2009},
}
